{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "065fd0c2-b43e-414e-9239-f2700f36146d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in ./anaconda3/lib/python3.11/site-packages (8.3.23)\n",
      "Requirement already satisfied: numpy>=1.23.0 in ./anaconda3/lib/python3.11/site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in ./anaconda3/lib/python3.11/site-packages (from ultralytics) (3.9.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in ./anaconda3/lib/python3.11/site-packages (from ultralytics) (4.9.0.80)\n",
      "Requirement already satisfied: pillow>=7.1.2 in ./anaconda3/lib/python3.11/site-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in ./anaconda3/lib/python3.11/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in ./anaconda3/lib/python3.11/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in ./anaconda3/lib/python3.11/site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in ./anaconda3/lib/python3.11/site-packages (from ultralytics) (2.5.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in ./anaconda3/lib/python3.11/site-packages (from ultralytics) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in ./anaconda3/lib/python3.11/site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in ./anaconda3/lib/python3.11/site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in ./anaconda3/lib/python3.11/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in ./anaconda3/lib/python3.11/site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in ./anaconda3/lib/python3.11/site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in ./anaconda3/lib/python3.11/site-packages (from ultralytics) (2.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./anaconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./anaconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./anaconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./anaconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./anaconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./anaconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./anaconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./anaconda3/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./anaconda3/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./anaconda3/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in ./anaconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./anaconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Requirement already satisfied: networkx in ./anaconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./anaconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./anaconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./anaconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./anaconda3/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in ./anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: opencv-python in ./anaconda3/lib/python3.11/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in ./anaconda3/lib/python3.11/site-packages (from opencv-python) (1.26.4)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n",
    "!pip install opencv-python\n",
    "!pip install deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1739d57b-7129-4527-9ed2-1de0ffc49bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Obtaining dependency information for gradio from https://files.pythonhosted.org/packages/a5/ba/18ad189474e730baa47697c55afd4ab7c0d19d429232f7b8f771f3fd76d5/gradio-5.4.0-py3-none-any.whl.metadata\n",
      "  Downloading gradio-5.4.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Obtaining dependency information for aiofiles<24.0,>=22.0 from https://files.pythonhosted.org/packages/c5/19/5af6804c4cc0fed83f47bff6e413a98a36618e7d40185cd36e69737f3b0e/aiofiles-23.2.1-py3-none-any.whl.metadata\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in ./anaconda3/lib/python3.11/site-packages (from gradio) (4.6.2)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Obtaining dependency information for fastapi<1.0,>=0.115.2 from https://files.pythonhosted.org/packages/57/95/4c5b79e7ca1f7b372d16a32cad7c9cc6c3c899200bed8f45739f4415cfae/fastapi-0.115.3-py3-none-any.whl.metadata\n",
      "  Downloading fastapi-0.115.3-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Obtaining dependency information for ffmpy from https://files.pythonhosted.org/packages/ff/1e/db99aa669eee301966bc6c997d60a0240f9cecae63f044b2e5a5310e4bf7/ffmpy-0.4.0-py3-none-any.whl.metadata\n",
      "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.4.2 (from gradio)\n",
      "  Obtaining dependency information for gradio-client==1.4.2 from https://files.pythonhosted.org/packages/e0/6f/9eb14d4e9ef366be2020063d91c4f608294969fcd7b9fcc48153c64b9776/gradio_client-1.4.2-py3-none-any.whl.metadata\n",
      "  Downloading gradio_client-1.4.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in ./anaconda3/lib/python3.11/site-packages (from gradio) (0.27.0)\n",
      "Collecting huggingface-hub>=0.25.1 (from gradio)\n",
      "  Obtaining dependency information for huggingface-hub>=0.25.1 from https://files.pythonhosted.org/packages/d7/4d/017d8d7cff5100092da8ea19139bcb1965bbadcbb5ddd0480e2badc299e8/huggingface_hub-0.26.1-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.26.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in ./anaconda3/lib/python3.11/site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in ./anaconda3/lib/python3.11/site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in ./anaconda3/lib/python3.11/site-packages (from gradio) (1.26.4)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Obtaining dependency information for orjson~=3.0 from https://files.pythonhosted.org/packages/79/bc/2a0eb0029729f1e466d5a595261446e5c5b6ed9213759ee56b6202f99417/orjson-3.10.10-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata\n",
      "  Downloading orjson-3.10.10-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in ./anaconda3/lib/python3.11/site-packages (from gradio) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in ./anaconda3/lib/python3.11/site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in ./anaconda3/lib/python3.11/site-packages (from gradio) (10.2.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in ./anaconda3/lib/python3.11/site-packages (from gradio) (2.8.2)\n",
      "Collecting pydub (from gradio)\n",
      "  Obtaining dependency information for pydub from https://files.pythonhosted.org/packages/a6/53/d78dc063216e62fc55f6b2eebb447f6a4b0a59f55c8406376f76bf959b08/pydub-0.25.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart==0.0.12 (from gradio)\n",
      "  Obtaining dependency information for python-multipart==0.0.12 from https://files.pythonhosted.org/packages/f5/0b/c316262244abea7481f95f1e91d7575f3dfcf6455d56d1ffe9839c582eb1/python_multipart-0.0.12-py3-none-any.whl.metadata\n",
      "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in ./anaconda3/lib/python3.11/site-packages (from gradio) (6.0.2)\n",
      "Collecting ruff>=0.2.2 (from gradio)\n",
      "  Obtaining dependency information for ruff>=0.2.2 from https://files.pythonhosted.org/packages/a2/31/7d14e2a88da351200f844b7be889a0845d9e797162cf76b136d21b832a23/ruff-0.7.1-py3-none-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading ruff-0.7.1-py3-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<1.0,>=0.1.1 (from gradio)\n",
      "  Obtaining dependency information for safehttpx<1.0,>=0.1.1 from https://files.pythonhosted.org/packages/df/f7/55cdeed5889f2076fdb125bc87bb7ab0f1715c84b0a4619c44833d890f60/safehttpx-0.1.1-py3-none-any.whl.metadata\n",
      "  Downloading safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Obtaining dependency information for semantic-version~=2.0 from https://files.pythonhosted.org/packages/6a/23/8146aad7d88f4fcb3a6218f41a60f6c2d4e3a72de72da1825dc7c8f7877c/semantic_version-2.10.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Obtaining dependency information for starlette<1.0,>=0.40.0 from https://files.pythonhosted.org/packages/54/43/f185bfd0ca1d213beb4293bed51d92254df23d8ceaf6c0e17146d508a776/starlette-0.41.2-py3-none-any.whl.metadata\n",
      "  Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio)\n",
      "  Obtaining dependency information for tomlkit==0.12.0 from https://files.pythonhosted.org/packages/68/4f/12207897848a653d03ebbf6775a29d949408ded5f99b2d87198bc5c93508/tomlkit-0.12.0-py3-none-any.whl.metadata\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Obtaining dependency information for typer<1.0,>=0.12 from https://files.pythonhosted.org/packages/a8/2b/886d13e742e514f704c33c4caa7df0f3b89e5a25ef8db02aa9ca3d9535d5/typer-0.12.5-py3-none-any.whl.metadata\n",
      "  Downloading typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in ./anaconda3/lib/python3.11/site-packages (from gradio) (4.11.0)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Obtaining dependency information for uvicorn>=0.14.0 from https://files.pythonhosted.org/packages/eb/14/78bd0e95dd2444b6caacbca2b730671d4295ccb628ef58b81bee903629df/uvicorn-0.32.0-py3-none-any.whl.metadata\n",
      "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: fsspec in ./anaconda3/lib/python3.11/site-packages (from gradio-client==1.4.2->gradio) (2024.6.1)\n",
      "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.2->gradio)\n",
      "  Obtaining dependency information for websockets<13.0,>=10.0 from https://files.pythonhosted.org/packages/95/aa/75fa3b893142d6d98a48cb461169bd268141f2da8bfca97392d6462a02eb/websockets-12.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading websockets-12.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: idna>=2.8 in ./anaconda3/lib/python3.11/site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./anaconda3/lib/python3.11/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: certifi in ./anaconda3/lib/python3.11/site-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in ./anaconda3/lib/python3.11/site-packages (from httpx>=0.24.1->gradio) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in ./anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.25.1->gradio) (3.13.1)\n",
      "Requirement already satisfied: requests in ./anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.25.1->gradio) (4.66.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./anaconda3/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./anaconda3/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./anaconda3/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./anaconda3/lib/python3.11/site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./anaconda3/lib/python3.11/site-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
      "Requirement already satisfied: click>=8.0.0 in ./anaconda3/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Obtaining dependency information for shellingham>=1.3.0 from https://files.pythonhosted.org/packages/e0/f9/0595336914c5619e5f28a1fb793285925a8cd4b432c9da0a987836c7f822/shellingham-1.5.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./anaconda3/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
      "Requirement already satisfied: six>=1.5 in ./anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./anaconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./anaconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.15.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n",
      "Downloading gradio-5.4.0-py3-none-any.whl (56.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.7/56.7 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-1.4.2-py3-none-any.whl (319 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.8/319.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
      "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading fastapi-0.115.3-py3-none-any.whl (94 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.26.1-py3-none-any.whl (447 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.4/447.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.10-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (270 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.7/270.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ruff-0.7.1-py3-none-macosx_11_0_arm64.whl (9.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.12.5-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m771.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading websockets-12.0-cp311-cp311-macosx_11_0_arm64.whl (121 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.3/121.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, tomlkit, shellingham, semantic-version, ruff, python-multipart, orjson, ffmpy, aiofiles, starlette, huggingface-hub, typer, safehttpx, gradio-client, fastapi, gradio\n",
      "  Attempting uninstall: tomlkit\n",
      "    Found existing installation: tomlkit 0.13.2\n",
      "    Uninstalling tomlkit-0.13.2:\n",
      "      Successfully uninstalled tomlkit-0.13.2\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface_hub 0.24.6\n",
      "    Uninstalling huggingface_hub-0.24.6:\n",
      "      Successfully uninstalled huggingface_hub-0.24.6\n",
      "Successfully installed aiofiles-23.2.1 fastapi-0.115.3 ffmpy-0.4.0 gradio-5.4.0 gradio-client-1.4.2 huggingface-hub-0.26.1 orjson-3.10.10 pydub-0.25.1 python-multipart-0.0.12 ruff-0.7.1 safehttpx-0.1.1 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.41.2 tomlkit-0.12.0 typer-0.12.5 uvicorn-0.32.0 websockets-12.0\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89be4b1-cb15-41ea-b929-eb0dcd90262c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaves in use: 10\n",
      "\n",
      "0: 512x640 1 person, 93.1ms\n",
      "Speed: 6.0ms preprocess, 93.1ms inference, 7.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 19), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 19), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 19), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 19), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 8), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 5), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 19), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 10), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 14), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 12), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 1 banana, 70.8ms\n",
      "Speed: 2.6ms preprocess, 70.8ms inference, 0.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 28), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 23), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 24), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 23), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 13), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 13), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 23), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 16), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 21), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 22), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 51.7ms\n",
      "Speed: 2.6ms preprocess, 51.7ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 36), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 31), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 34), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 31), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 23), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 20), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 30), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 20), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 25), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 32), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 48.5ms\n",
      "Speed: 1.8ms preprocess, 48.5ms inference, 0.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 43), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 38), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 42), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 35), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 30), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 27), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 40), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 24), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 29), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 41), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 56.3ms\n",
      "Speed: 2.1ms preprocess, 56.3ms inference, 0.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 53), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 46), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 52), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 39), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 35), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 31), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 46), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 30), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 35), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 48), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 44.9ms\n",
      "Speed: 1.9ms preprocess, 44.9ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 58), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 54), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 62), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 47), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 45), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 35), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 52), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 35), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 39), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 57), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 46.1ms\n",
      "Speed: 1.9ms preprocess, 46.1ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 67), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 58), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 70), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 57), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 53), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 40), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 59), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 43), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 45), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 61), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 96.4ms\n",
      "Speed: 2.1ms preprocess, 96.4ms inference, 0.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 76), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 67), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 79), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 64), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 59), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 46), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 67), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 52), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 55), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 65), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 57.2ms\n",
      "Speed: 2.1ms preprocess, 57.2ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 80), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 77), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 87), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 71), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 67), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 54), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 71), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 61), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 63), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 71), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 58.1ms\n",
      "Speed: 2.0ms preprocess, 58.1ms inference, 0.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 85), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 84), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 91), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 75), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 77), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 62), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 78), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 68), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 71), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 80), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 41.3ms\n",
      "Speed: 2.1ms preprocess, 41.3ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 95), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 92), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 100), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 79), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 85), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 68), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 85), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 76), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 79), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 88), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 47.4ms\n",
      "Speed: 1.9ms preprocess, 47.4ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 101), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 97), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 105), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 89), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 95), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 72), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 90), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 83), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 87), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 92), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 48.2ms\n",
      "Speed: 1.8ms preprocess, 48.2ms inference, 0.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 107), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 107), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 111), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 98), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 103), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 80), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 97), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 89), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 96), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 100), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 57.4ms\n",
      "Speed: 2.0ms preprocess, 57.4ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 113), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 113), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 120), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 102), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 107), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 86), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 106), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 98), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 106), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 106), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 76.3ms\n",
      "Speed: 2.8ms preprocess, 76.3ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 118), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 120), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 124), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 109), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 111), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 94), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 110), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 105), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 114), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 110), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 106.2ms\n",
      "Speed: 2.0ms preprocess, 106.2ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 125), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 124), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 130), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 117), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 116), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 98), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 114), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 115), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 124), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 120), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 47.4ms\n",
      "Speed: 2.1ms preprocess, 47.4ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 134), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 131), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 140), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 121), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 123), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 104), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 124), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 123), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 132), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 125), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 53.1ms\n",
      "Speed: 1.9ms preprocess, 53.1ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 142), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 141), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 147), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 130), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 128), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 112), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 133), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 127), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 140), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 130), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 46.8ms\n",
      "Speed: 1.8ms preprocess, 46.8ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 147), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 147), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 154), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 140), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 132), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 121), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 140), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 131), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 146), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 139), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 49.6ms\n",
      "Speed: 2.0ms preprocess, 49.6ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 154), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 151), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 162), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 150), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 136), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 125), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 149), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 139), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 155), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 145), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 1 sports ball, 44.6ms\n",
      "Speed: 2.5ms preprocess, 44.6ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 161), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 160), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 171), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 157), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 146), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 132), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 158), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 144), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 159), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 152), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 1 cup, 69.2ms\n",
      "Speed: 2.1ms preprocess, 69.2ms inference, 0.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 166), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 166), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 181), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 162), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 153), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 138), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 167), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 151), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 166), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 161), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 45.1ms\n",
      "Speed: 8.9ms preprocess, 45.1ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 171), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 176), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 187), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 170), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 158), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 146), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 177), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 157), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 175), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 166), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 55.9ms\n",
      "Speed: 1.9ms preprocess, 55.9ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 181), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 181), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 197), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 180), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 163), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 154), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 187), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 167), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 180), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 170), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 43.6ms\n",
      "Speed: 2.1ms preprocess, 43.6ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 189), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 188), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 203), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 189), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 173), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 158), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 191), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 174), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 184), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 174), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 67.5ms\n",
      "Speed: 2.1ms preprocess, 67.5ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 195), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 197), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 210), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 197), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 181), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 167), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 196), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 181), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 190), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 178), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 97.6ms\n",
      "Speed: 1.9ms preprocess, 97.6ms inference, 0.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 200), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 205), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 220), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 203), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 187), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 174), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 206), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 185), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 197), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 185), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 72.3ms\n",
      "Speed: 2.4ms preprocess, 72.3ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 210), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 210), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 224), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 210), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 193), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 181), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 211), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 192), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 205), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 194), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 48.4ms\n",
      "Speed: 2.1ms preprocess, 48.4ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 216), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 217), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 229), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 215), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 199), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 185), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 220), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 197), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 211), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 199), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 44.9ms\n",
      "Speed: 1.9ms preprocess, 44.9ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 220), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 221), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 237), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 220), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 203), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 191), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 228), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 203), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 217), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 208), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 1 orange, 53.2ms\n",
      "Speed: 1.8ms preprocess, 53.2ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 225), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 230), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 241), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 226), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 213), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 196), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 237), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 208), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 221), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 218), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 1 orange, 44.0ms\n",
      "Speed: 2.0ms preprocess, 44.0ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 235), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 238), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 249), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 232), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 217), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 205), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 244), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 212), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 227), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 222), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 1 cup, 186.6ms\n",
      "Speed: 8.5ms preprocess, 186.6ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 242), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 245), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 255), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 238), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 227), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 210), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 253), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 220), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 232), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 227), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 1 cup, 49.0ms\n",
      "Speed: 1.8ms preprocess, 49.0ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 250), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 251), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 261), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 247), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 234), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 219), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 260), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 225), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 237), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 233), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 1 cup, 1 orange, 44.0ms\n",
      "Speed: 1.8ms preprocess, 44.0ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 256), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 256), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 265), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 251), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 239), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 229), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 264), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 235), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 243), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 237), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 1 cup, 1 orange, 43.5ms\n",
      "Speed: 1.9ms preprocess, 43.5ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Overlaying leaf 0: position (87, 265), size (100, 100)\n",
      "Overlaying leaf 1: position (192, 260), size (100, 100)\n",
      "Overlaying leaf 2: position (382, 274), size (100, 100)\n",
      "Overlaying leaf 3: position (570, 255), size (100, 100)\n",
      "Overlaying leaf 4: position (747, 244), size (100, 100)\n",
      "Overlaying leaf 5: position (1054, 237), size (100, 100)\n",
      "Overlaying leaf 6: position (1148, 270), size (100, 100)\n",
      "Overlaying leaf 7: position (1353, 240), size (100, 100)\n",
      "Overlaying leaf 8: position (1534, 252), size (100, 100)\n",
      "Overlaying leaf 9: position (1603, 246), size (100, 100)\n",
      "\n",
      "0: 512x640 1 person, 2 cups, 1 orange, 46.1ms\n",
      "Speed: 1.9ms preprocess, 46.1ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from deepface import DeepFace\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Load YOLO model for object detection\n",
    "model = YOLO(\"yolo11n.pt\")  # Adjust path if using another YOLO model\n",
    "\n",
    "# COCO class names (trimmed for brevity, expand as needed)\n",
    "COCO_CLASSES = [\"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\", \n",
    "                \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\", \n",
    "                \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \n",
    "                \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \n",
    "                \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \n",
    "                \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \n",
    "                \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \n",
    "                \"chair\", \"couch\", \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"tv\", \"laptop\", \n",
    "                \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \n",
    "                \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \n",
    "                \"toothbrush\"]\n",
    "\n",
    "# Items and emotions contributing to the fall score\n",
    "FALL_OBJECTS = {\"cup\": 10, \"orange\": 10, \"cat\": 8, \"dog\": 8, \"bottle\": 8, \"wine glass\": 8, \"bowl\": 6, \"teddy bear\": 6,\n",
    "                \"vase\": 6, \"umbrella\": 5, \"handbag\": 4, \"backpack\": 3, \"bench\": 2, \"chair\": 3, \"couch\": 4,\n",
    "                \"potted plant\": 5, \"book\": 7, \"clock\": 2, \"tv\": 2}\n",
    "FALL_EMOTIONS = {\"sad\": 10, \"neutral\": 5}\n",
    "\n",
    "# Load leaf images and print dimensions for verification\n",
    "leaf_images = []\n",
    "for i in range(1, 5):\n",
    "    leaf = cv.imread(f'leaves/leaf{i}.png', cv.IMREAD_UNCHANGED)\n",
    "    if leaf is not None:\n",
    "        leaf_images.append(leaf)\n",
    "    else:\n",
    "        print(f\"Failed to load leaf{i}.png\")\n",
    "\n",
    "# Replicate leaves\n",
    "num_leaves = 10\n",
    "if len(leaf_images) < num_leaves:\n",
    "    # Repeat the leaf images to reach the desired number of leaves\n",
    "    leaf_images = leaf_images * (num_leaves // len(leaf_images)) + leaf_images[:num_leaves % len(leaf_images)]\n",
    "\n",
    "# Now `leaf_images` should have exactly `num_leaves` elements\n",
    "print(f\"Number of leaves in use: {len(leaf_images)}\")\n",
    "\n",
    "# Initialize video capture\n",
    "# Initialize video capture\n",
    "cap = cv.VideoCapture(0)\n",
    "cap.set(cv.CAP_PROP_FRAME_WIDTH, 800)\n",
    "cap.set(cv.CAP_PROP_FRAME_HEIGHT, 600)\n",
    "\n",
    "# Initialize leaf positions to be distributed evenly across the frame width\n",
    "frame_width = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "segment_width = frame_width // num_leaves\n",
    "\n",
    "leaf_positions = [\n",
    "    {\"x\": random.randint(i * segment_width, (i + 1) * segment_width - 1), \"y\": random.randint(0, 20)}\n",
    "    for i in range(num_leaves)\n",
    "]\n",
    "\n",
    "def animate_leaves(frame):\n",
    "    \"\"\" Animate falling leaves on the frame. \"\"\"\n",
    "    for i, leaf in enumerate(leaf_images):\n",
    "        leaf_pos = leaf_positions[i]\n",
    "        x, y = leaf_pos[\"x\"], leaf_pos[\"y\"]\n",
    "        h, w, _ = leaf.shape\n",
    "\n",
    "        # Ensure the leaf stays within the frame width\n",
    "        if x + w > frame.shape[1]:\n",
    "            x = frame.shape[1] - w\n",
    "\n",
    "        # Ensure the leaf stays within the frame height\n",
    "        if y + h > frame.shape[0]:\n",
    "            y = frame.shape[0] - h\n",
    "\n",
    "        # Debugging: Print leaf position and size\n",
    "        print(f\"Overlaying leaf {i}: position ({x}, {y}), size ({h}, {w})\")\n",
    "\n",
    "        # Overlay the leaf image on the frame\n",
    "        overlay_image_alpha(frame, leaf, x, y, leaf)\n",
    "\n",
    "        # Update leaf position for the next frame to fall faster\n",
    "        leaf_pos[\"y\"] += random.randint(4, 10)  # Increased speed to make leaves more noticeable\n",
    "\n",
    "        # Reset leaf position if it moves off-screen\n",
    "        if y > frame.shape[0]:\n",
    "            leaf_pos[\"y\"] = random.randint(-30, -10)  # Reduced reset range for quicker visibility\n",
    "            leaf_pos[\"x\"] = random.randint(i * segment_width, (i + 1) * segment_width - w)\n",
    "\n",
    "def get_class_label(class_id):\n",
    "    if 0 <= class_id < len(COCO_CLASSES):\n",
    "        return COCO_CLASSES[class_id]\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "def analyze_emotion(face_img):\n",
    "    try:\n",
    "        result = DeepFace.analyze(face_img, actions=['emotion'], enforce_detection=False)\n",
    "        if isinstance(result, list):\n",
    "            result = result[0]\n",
    "        dominant_emotion = result[\"dominant_emotion\"]\n",
    "        confidence = result[\"emotion\"][dominant_emotion]\n",
    "        return dominant_emotion, confidence\n",
    "    except Exception as e:\n",
    "        print(f\"DeepFace error: {e}\")\n",
    "        return \"No emotion detected\", 0.0\n",
    "\n",
    "def calculate_fall_score(detected_objects, dominant_emotion):\n",
    "    fall_score = 0\n",
    "    for obj in detected_objects:\n",
    "        label = obj[\"label\"]\n",
    "        if label in FALL_OBJECTS:\n",
    "            fall_score += FALL_OBJECTS[label]\n",
    "    if dominant_emotion in FALL_EMOTIONS:\n",
    "        fall_score += FALL_EMOTIONS[dominant_emotion]\n",
    "    return fall_score\n",
    "\n",
    "def overlay_image_alpha(background, overlay, x, y, alpha_mask):\n",
    "    \"\"\" Overlay `overlay` onto `background` at position (x, y) with an alpha mask. \"\"\"\n",
    "    h, w, _ = overlay.shape\n",
    "    background_h, background_w, _ = background.shape\n",
    "\n",
    "    if x < 0 or y < 0:\n",
    "        return\n",
    "\n",
    "    if x + w > background_w:\n",
    "        w = background_w - x\n",
    "    if y + h > background_h:\n",
    "        h = background_h - y\n",
    "\n",
    "    if w <= 0 or h <= 0:\n",
    "        return\n",
    "\n",
    "    overlay_image = overlay[:h, :w, :3]\n",
    "    mask = alpha_mask[:h, :w, 3] / 255.0\n",
    "\n",
    "    for c in range(3):\n",
    "        background[y:y+h, x:x+w, c] = (1.0 - mask) * background[y:y+h, x:x+w, c] + mask * overlay_image[:, :, c]\n",
    "\n",
    "# Function to draw multi-line text on the frame\n",
    "def draw_multiline_text(frame, text, font, font_scale, color, thickness, line_spacing=1.5):\n",
    "    \"\"\" Draw multi-line text centered on an OpenCV frame. \"\"\"\n",
    "    # Split the text into lines\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # Get the frame dimensions\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "    # Calculate the total height of all lines combined\n",
    "    total_text_height = int(len(lines) * font_scale * 30 * line_spacing)\n",
    "\n",
    "    # Calculate the y-coordinate to start the text block so that it is centered vertically\n",
    "    y_start = (frame_height - total_text_height) // 2\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        # Calculate the width of each line to center it horizontally\n",
    "        text_size = cv.getTextSize(line, font, font_scale, thickness)[0]\n",
    "        x = (frame_width - text_size[0]) // 2\n",
    "\n",
    "        # Calculate the y-coordinate for each line\n",
    "        y = y_start + int(i * font_scale * 30 * line_spacing)\n",
    "\n",
    "        # Draw the line on the frame\n",
    "        cv.putText(frame, line, (x, y), font, font_scale, color, thickness, cv.LINE_AA)\n",
    "\n",
    "def process_results(results, frame):\n",
    "    detected_objects = []\n",
    "    dominant_emotion = \"neutral\"\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "    for box in results[0].boxes:\n",
    "        class_id = int(box.cls)\n",
    "        label = get_class_label(class_id)\n",
    "        x_min, y_min, x_max, y_max = map(int, box.xyxy[0])\n",
    "        confidence = box.conf\n",
    "        detected_objects.append({\n",
    "            \"label\": label,\n",
    "            \"coordinates\": (x_min, y_min, x_max, y_max),\n",
    "            \"confidence\": confidence\n",
    "        })\n",
    "        \n",
    "        cv.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "        cv.putText(frame, label, (x_min, max(y_min - 10, 0)), cv.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "        if label == \"person\":\n",
    "            face_img = frame[y_min:y_max, x_min:x_max]\n",
    "            if face_img.size == 0:\n",
    "                continue\n",
    "            emotion_label, confidence = analyze_emotion(face_img)\n",
    "            dominant_emotion = emotion_label\n",
    "            text_x, text_y = max(x_min, 0), min(y_max + 30, frame_height - 10)\n",
    "            cv.putText(frame, f\"Emotion: {emotion_label} ({confidence:.2f})\", \n",
    "                       (text_x, text_y), \n",
    "                       cv.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "    \n",
    "    fall_score = calculate_fall_score(detected_objects, dominant_emotion)\n",
    "    \n",
    "    if fall_score > 25:\n",
    "        draw_multiline_text(\n",
    "            frame, \n",
    "            \"It seems like the 'Hoa Hoa Hoa Season' has started for you.\\nGrab some snacks, a blanket, and enjoy a timeless masterpiece!\", \n",
    "            font=cv.FONT_HERSHEY_SIMPLEX, \n",
    "            font_scale=1.2, \n",
    "            color=(0, 0, 255), \n",
    "            thickness=3, \n",
    "            line_spacing=1.5  # Adjust line spacing as needed\n",
    "        )\n",
    "        cv.imshow(\"Emotion Recognition and Fall Score\", frame)\n",
    "        cv.waitKey(0)\n",
    "        return detected_objects, fall_score\n",
    "\n",
    "    cv.putText(frame, f\"Fall Score: {fall_score}\", \n",
    "               (10, 30), \n",
    "               cv.FONT_HERSHEY_SIMPLEX, 0.8, (0, 165, 255), 2)\n",
    "\n",
    "    animate_leaves(frame)\n",
    "\n",
    "    return detected_objects, fall_score\n",
    "\n",
    "# Start time for the 3-second delay\n",
    "start_time = time.time()\n",
    "max_duration = 5\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Measure elapsed time\n",
    "    elapsed_time = time.time() - start_time\n",
    "    if elapsed_time < max_duration:\n",
    "        # Display the live feed for the defined period without calculating the fall score\n",
    "        cv.imshow(\"Emotion Recognition and Fall Score\", frame)\n",
    "\n",
    "        # Break if 'q' is pressed\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        continue\n",
    "    \n",
    "    # Once 3 seconds have passed, process the frame\n",
    "    results = model(frame)\n",
    "    detected_objects, fall_score = process_results(results, frame)\n",
    "    \n",
    "    # Show the final frame with labels, emotions, and fall score\n",
    "    cv.imshow(\"Emotion Recognition and Fall Score\", frame)\n",
    "\n",
    "    # Introduce a delay to control the frame rate\n",
    "    key = cv.waitKey(33)  # Approximately 30 FPS (1000 ms / 30)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a602d1-e5d0-4507-8a2c-cb633f93ff0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
